{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np2BrvV0vpP6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from scipy.sparse import hstack, csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-GWUK8Z9DJV"
      },
      "outputs": [],
      "source": [
        "# ------------- data (sama seperti yang dipakai sebelumnya) -------------\n",
        "train_data = {\n",
        "    'review': [\n",
        "        'Kameranya bagus banget, hasilnya jernih!',\n",
        "        'Baterai awet seharian, performa kencang.',\n",
        "        'Suka sama desainnya, premium dan elegan.',\n",
        "        'Pengiriman cepat, packing aman, produk original.',\n",
        "        'Mantap, sesuai ekspektasi. Tidak mengecewakan.',\n",
        "        'Baru dipakai sebentar sudah panas, kecewa.',\n",
        "        'Layar sering tidak merespon, sangat mengganggu.',\n",
        "        'Barangnya rusak pas sampai, pengemasannya buruk.',\n",
        "        'Kualitas suara speakernya jelek sekali.',\n",
        "        'Deskripsi tidak sesuai, banyak fitur yang hilang.'\n",
        "    ],\n",
        "    'sentiment': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "}\n",
        "df = pd.DataFrame(train_data)\n",
        "\n",
        "eval_data = {\n",
        "    'review': [\n",
        "        'Kameranya luar biasa, detail foto sangat tajam.',\n",
        "        'Baterai cepat sekali habis, bikin kecewa.',\n",
        "        'Desain ponselnya keren, ringan dan tipis.',\n",
        "        'Sinyal sering hilang, sangat merepotkan.',\n",
        "        'Layar AMOLED-nya jernih, nyaman dipakai nonton.',\n",
        "        'Charger tidak berfungsi, produk cacat.',\n",
        "        'Speaker suaranya mantap, bass terasa.',\n",
        "        'Aplikasi sering force close, tidak stabil.',\n",
        "        'Body kokoh, terasa premium di tangan.',\n",
        "        'Harga mahal tapi kualitas buruk.'\n",
        "    ]\n",
        "}\n",
        "eval_df = pd.DataFrame(eval_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UGlyT969xIv"
      },
      "outputs": [],
      "source": [
        "# ------------- resources -------------\n",
        "# Pastikan Anda sudah mendownload 'stopwords' NLTK\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('stopwords')\n",
        "except nltk.downloader.DownloadEvicted:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "\n",
        "# JANGAN hapus kata negasi â€” keluarkan dari stopwords\n",
        "negation_words = {'tidak', 'bukan', 'jangan', 'belum', 'kurang'}\n",
        "stop_words = stop_words - negation_words\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8vdU4gt91L_"
      },
      "outputs": [],
      "source": [
        "# ------------- preproc (keep negation) -------------\n",
        "def clean_text_keep_neg(text):\n",
        "    text = text.lower()\n",
        "    # pertahankan spasi dan huruf, tapi hapus angka/simbol kecuali '-'\n",
        "    text = re.sub(r'[^a-z\\s\\-]', ' ', text)\n",
        "    # collapse multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def tokenize_and_stem(text):\n",
        "    # tokenisasi sederhana, lalu hapus stopwords (tetap menyimpan negasi)\n",
        "    toks = text.split()\n",
        "    toks = [t for t in toks if t not in stop_words]\n",
        "    stems = [stemmer.stem(t) for t in toks]\n",
        "    return stems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdJbmvBr95Vg"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to training + eval\n",
        "df['clean'] = df['review'].apply(clean_text_keep_neg)\n",
        "df['tokens'] = df['clean'].apply(tokenize_and_stem)\n",
        "\n",
        "eval_df['clean'] = eval_df['review'].apply(clean_text_keep_neg)\n",
        "eval_df['tokens'] = eval_df['clean'].apply(tokenize_and_stem)\n",
        "\n",
        "# ------------- buat lexicon sederhana (bisa dikembangkan) -------------\n",
        "pos_lex = ['bagus','awet','jernih','kencang','premium','elegan','aman','mantap','tajam','nyaman','mantap','keren','mantap','baik','bagus']\n",
        "neg_lex = ['rusak','buruk','kecewa','jelek','hilang','panas','ganggu','cacat','tidak','pengecew','gagal','tidakfungsi','tidak_berfungsi','tidak_ada']\n",
        "\n",
        "# stem lexicon supaya cocok dengan hasil stemmer\n",
        "pos_lex_stem = set([stemmer.stem(w) for w in pos_lex])\n",
        "neg_lex_stem = set([stemmer.stem(w) for w in neg_lex])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aii-8qhG98P7"
      },
      "outputs": [],
      "source": [
        "# --- PERBAIKAN ---\n",
        "# Ganti lexicon_score dengan hitungan positif dan negatif terpisah (non-negatif)\n",
        "def lexicon_counts(stems):\n",
        "    pos_count = sum(1 for w in stems if w in pos_lex_stem)\n",
        "    neg_count = sum(1 for w in stems if w in neg_lex_stem)\n",
        "    return pos_count, neg_count\n",
        "\n",
        "def has_negation(text):\n",
        "    for neg in negation_words:\n",
        "        if f' {neg} ' in f' {text} ':  # crude check\n",
        "            return 1\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yp2kEH69_Ld"
      },
      "outputs": [],
      "source": [
        "# Apply new lexicon features\n",
        "df['pos_score'], df['neg_score'] = zip(*df['tokens'].apply(lexicon_counts))\n",
        "df['has_neg'] = df['clean'].apply(has_negation)\n",
        "\n",
        "eval_df['pos_score'], eval_df['neg_score'] = zip(*eval_df['tokens'].apply(lexicon_counts))\n",
        "eval_df['has_neg'] = eval_df['clean'].apply(has_negation)\n",
        "\n",
        "# ------------- vectorization TF-IDF dengan n-grams -------------\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.85, sublinear_tf=True)\n",
        "X_tfidf = vectorizer.fit_transform(df['clean'])\n",
        "y = df['sentiment'].values\n",
        "\n",
        "# tambahkan fitur numerik pos_score, neg_score, & has_neg ke matriks TF-IDF\n",
        "# --- PERBAIKAN ---\n",
        "# Gunakan pos_score dan neg_score yang non-negatif\n",
        "X_extra = csr_matrix(np.vstack([df['pos_score'].values, df['neg_score'].values, df['has_neg'].values]).T)\n",
        "X = hstack([X_tfidf, X_extra])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As6hdmTr-B54",
        "outputId": "7a3dd433-e806-44c5-885a-9d8ed2fd12c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best NB: {'alpha': 0.01} cv score: 0.875\n",
            "Best SVM: {'C': 0.01, 'class_weight': None} cv score: 0.875\n"
          ]
        }
      ],
      "source": [
        "# ------------- GridSearch / CV untuk NB dan SVM -------------\n",
        "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "# NB tuning (sekarang seharusnya tidak error karena input non-negatif)\n",
        "nb = MultinomialNB()\n",
        "params_nb = {'alpha': [0.01, 0.1, 0.5, 1.0]} # Added more alpha values for tuning\n",
        "gs_nb = GridSearchCV(nb, params_nb, cv=cv, scoring='accuracy')\n",
        "gs_nb.fit(X, y)\n",
        "best_nb = gs_nb.best_estimator_\n",
        "\n",
        "# SVM tuning (gunakan class_weight dan C)\n",
        "svm = LinearSVC(max_iter=5000, dual=True) # dual=True is often faster for n_samples > n_features\n",
        "params_svm = {'C': [0.01, 0.1, 1, 10, 100], 'class_weight': [None, 'balanced']} # Added C=100\n",
        "gs_svm = GridSearchCV(svm, params_svm, cv=cv, scoring='accuracy')\n",
        "gs_svm.fit(X, y)\n",
        "best_svm = gs_svm.best_estimator_\n",
        "\n",
        "print(\"Best NB:\", gs_nb.best_params_, \"cv score:\", gs_nb.best_score_)\n",
        "print(\"Best SVM:\", gs_svm.best_params_, \"cv score:\", gs_svm.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIMpMEpa-EbS",
        "outputId": "a0796143-1a49-4a6a-8261-c0fde1586123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Hasil Prediksi Sentimen pada Dataset Evaluasi ===\n",
            "\n",
            "                                         review NB_pred SVM_pred VOTE_pred\n",
            "Kameranya luar biasa, detail foto sangat tajam. Positif  Positif   Positif\n",
            "      Baterai cepat sekali habis, bikin kecewa. Negatif  Negatif   Negatif\n",
            "      Desain ponselnya keren, ringan dan tipis. Positif  Positif   Positif\n",
            "       Sinyal sering hilang, sangat merepotkan. Negatif  Negatif   Negatif\n",
            "Layar AMOLED-nya jernih, nyaman dipakai nonton. Positif  Positif   Positif\n",
            "         Charger tidak berfungsi, produk cacat. Negatif  Negatif   Negatif\n",
            "          Speaker suaranya mantap, bass terasa. Positif  Positif   Positif\n",
            "     Aplikasi sering force close, tidak stabil. Negatif  Negatif   Negatif\n",
            "          Body kokoh, terasa premium di tangan. Positif  Positif   Positif\n",
            "               Harga mahal tapi kualitas buruk. Negatif  Negatif   Negatif\n"
          ]
        }
      ],
      "source": [
        "# ------------- Ensemble voting (hard) -------------\n",
        "# Train the best models on the full training data before ensembling\n",
        "best_nb.fit(X, y)\n",
        "best_svm.fit(X, y)\n",
        "\n",
        "voting = VotingClassifier(estimators=[('nb', best_nb), ('svm', best_svm)], voting='hard')\n",
        "voting.fit(X, y)\n",
        "\n",
        "# ------------- prepare eval features -------------\n",
        "X_eval_tfidf = vectorizer.transform(eval_df['clean'])\n",
        "# --- PERBAIKAN ---\n",
        "# Gunakan pos_score dan neg_score non-negatif untuk data evaluasi\n",
        "X_eval_extra = csr_matrix(np.vstack([eval_df['pos_score'].values, eval_df['neg_score'].values, eval_df['has_neg'].values]).T)\n",
        "X_eval = hstack([X_eval_tfidf, X_eval_extra])\n",
        "\n",
        "# Prediksi\n",
        "eval_df['NB_pred'] = best_nb.predict(X_eval)\n",
        "eval_df['SVM_pred'] = best_svm.predict(X_eval)\n",
        "eval_df['VOTE_pred'] = voting.predict(X_eval)\n",
        "\n",
        "# label mapping\n",
        "label_map = {0: 'Negatif', 1: 'Positif'}\n",
        "for col in ['NB_pred','SVM_pred','VOTE_pred']:\n",
        "    eval_df[col] = eval_df[col].map(label_map)\n",
        "\n",
        "print(\"\\n=== Hasil Prediksi Sentimen pada Dataset Evaluasi ===\\n\")\n",
        "print(eval_df[['review','NB_pred','SVM_pred','VOTE_pred']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfRb-lUG-HAT",
        "outputId": "9e603531-01cb-431d-b07d-e82bdbacc32a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "-- Misclassified in train set (index, true, pred, review) --\n",
            "4 1 0 Mantap, sesuai ekspektasi. Tidak mengecewakan.\n"
          ]
        }
      ],
      "source": [
        "# ------------- analisis kesalahan pada data train (contoh) -------------\n",
        "# training predictions to inspect misclassifications\n",
        "# Use the voting classifier for misclassification analysis\n",
        "y_pred_train = voting.predict(X)\n",
        "# Find indices where prediction is not equal to true label\n",
        "mis_idx = np.where(y_pred_train != y)[0]\n",
        "print(\"\\n-- Misclassified in train set (index, true, pred, review) --\")\n",
        "if len(mis_idx) > 0:\n",
        "    for i in mis_idx:\n",
        "        print(i, y[i], y_pred_train[i], df.loc[i, 'review'])\n",
        "else:\n",
        "    print(\"No misclassifications found in the training set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLIWZQiC-Iew",
        "outputId": "f345ffba-64ab-487d-9cc7-b355bc0636ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top positive features (SVM):\n",
            "pos_score (0.126)\n",
            "tidak mengecewakan (0.007)\n",
            "sesuai ekspektasi (0.007)\n",
            "ekspektasi (0.007)\n",
            "ekspektasi tidak (0.007)\n",
            "mantap (0.007)\n",
            "mantap sesuai (0.007)\n",
            "mengecewakan (0.007)\n",
            "pengiriman cepat (0.005)\n",
            "packing (0.005)\n",
            "pengiriman (0.005)\n",
            "packing aman (0.005)\n",
            "aman produk (0.005)\n",
            "aman (0.005)\n",
            "cepat packing (0.005)\n",
            "\n",
            "Top negative features (SVM):\n",
            "neg_score (-0.100)\n",
            "has_neg (-0.010)\n",
            "kualitas suara (-0.006)\n",
            "kualitas (-0.006)\n",
            "suara (-0.006)\n",
            "speakernya jelek (-0.006)\n",
            "jelek sekali (-0.006)\n",
            "jelek (-0.006)\n",
            "suara speakernya (-0.006)\n",
            "speakernya (-0.006)\n",
            "sekali (-0.006)\n",
            "merespon sangat (-0.005)\n",
            "mengganggu (-0.005)\n",
            "merespon (-0.005)\n",
            "layar sering (-0.005)\n"
          ]
        }
      ],
      "source": [
        "# ------------- inspection: top features dari SVM -------------\n",
        "# hanya jika SVM terlatih linier -> ambil coef\n",
        "try:\n",
        "    feat_names = list(vectorizer.get_feature_names_out()) + ['pos_score','neg_score','has_neg'] # Update feature names\n",
        "    coef = best_svm.coef_[0]\n",
        "    top_pos = np.argsort(coef)[-15:][::-1]\n",
        "    top_neg = np.argsort(coef)[:15]\n",
        "    print(\"\\nTop positive features (SVM):\")\n",
        "    for idx in top_pos:\n",
        "        print(feat_names[idx], f\"({coef[idx]:.3f})\")\n",
        "    print(\"\\nTop negative features (SVM):\")\n",
        "    for idx in top_neg:\n",
        "        print(feat_names[idx], f\"({coef[idx]:.3f})\")\n",
        "except Exception as e:\n",
        "    print(\"Tidak bisa mengekstrak fitur SVM:\", e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
